# -*- coding: utf-8 -*-
"""ML Supervised - Regression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1THCbZ4wYP-I77E9qr40ZqCOm50ilGPJ8

## Contexto

The dataset includes 244 instances that regroup a data of two regions of Algeria (Bejaia region and Sidi Bel-abbes region) (122 instances for each region).

The observed period is from June 2012 to September 2012.

The dataset includes attributes and the 244 instances have been classified into fire (138 classes) and not fire (106 classes) classes, depending on the Fire Weather Index.

This dataset can be used for both regression model (using Fire Weather Index as target) or classification model (using Clases as target)

# Regression Model

## Configurações
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet, LassoCV, RidgeCV, ElasticNetCV
from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error

"""## Import and Clean data

**Import**
"""

df = pd.read_csv('Algerian_forest_fires_dataset_UPDATE.csv',header=1)

df.shape

"""**Clean**"""

df[df.isnull().any(axis=1)] #só devolve onde há alguma linha missing

#Arruma a base, marcando região 0 e remove linhas 122 e 123 que não são observações
df.loc[:121,'Region'] = 0
df.loc[124:,'Region'] = 1

df.loc[121:124,:]

df = df[df['Region'].isin([0,1])]

#checa demais missing novamente
df[df.isnull().any(axis=1)] #só devolve onde há alguma linha missing

#remove linha com erro de formatação
df2 = df.drop(167,axis=0).reset_index()

#checa demais missing novamente
df2[df2.isnull().any(axis=1)] #ok

"""**Arruma columns names**"""

df2.columns

df2.columns = df2.columns.str.strip() #para tirar só espaços em branco
df2 = df2.rename({'Classes':'class_fire'},axis=1)

df2.columns

"""**Ajusta datatypes**"""

df2.info()

df2[['day','month','year','Temperature','RH','Ws','Region']] = df2[['day','month','year','Temperature','RH','Ws','Region']].astype(int)

features_object = [features for features in df2.columns if df2[features].dtypes == 'O']
features_object

for i in features_object:
    if i != 'class_fire':
      df2[i] = df2[i].astype(float)

df2.info()

"""## Público

- Nível do modelo: região
- Datas de observação: june.12 to september.12

**Checar duplicidade**
"""

check_dup = df2.groupby(['day','month','year','Region'])['class_fire'].count().reset_index()
check_dup[check_dup['class_fire']>1] # ok

"""**Análise descritiva**"""

#df2.groupby('Region')['class_fire'].count().reset_index()
print(df2['Region'].value_counts())
print(df2['Region'].value_counts(normalize=1))

"""## Variável resposta

- Fire Weather Index
"""

df2[['FWI']].describe()

plt.boxplot(df2['FWI'])
plt.title('Fire Weather Index')
plt.annotate('O índice varia de 0 a 31, com média 7 e mediana 4.2',
            xy=(0.5,0.5), #comentário sobre este ponto (qualquer um, só para aparecer a caixa)
            xytext=(1.5, 0.5), #posição do texto
            fontsize=10,
             color='red')

df2.groupby('Region')['FWI'].describe()

df2.boxplot(column='FWI',by='Region', patch_artist=True)
plt.title('Fire Weather Index')
plt.annotate('A região 1 (Sidi) possui maiores'+'\n'+'índices de incêndios',
            xy=(0.5,0.5), #comentário sobre este ponto (qualquer um, só para aparecer a caixa)
            xytext=(2.7, 0.5), #posição do texto
            fontsize=10,
             color='red')
plt.show()

df2['class_fire'] = df2['class_fire'].str.strip() #havia respostas com espaço
df2.groupby('class_fire')['FWI'].describe()

df2.boxplot(column='FWI',by='class_fire', patch_artist=True)
plt.title('Fire Weather Index')
plt.annotate('Casos indicados como Fire possuem maiores'+'\n'+'índices de incêndios,como esperado',
            xy=(0.5,0.5), #comentário sobre este ponto (qualquer um, só para aparecer a caixa)
            xytext=(2.7, 0.5), #posição do texto
            fontsize=10,
             color='red')
plt.show()

df_reg0 = df2[df2['Region']==0]
df_reg1 = df2[df2['Region']==1]

plt.subplots(figsize=(8,3))

plt.subplot(1, 2, 1)
plt.title('Região 0')
sns.countplot(x='month',hue='class_fire',data=df_reg0)

plt.subplot(1, 2, 2)
plt.title('Região 1')
sns.countplot(x='month',hue='class_fire',data=df_reg1)

plt.annotate('Região 0 (Bejaia) teve um pico em agosto, revertido em setembro'+'\n'+'Região 1 (Sidi) teve picos em julho e agosto',
            xy=(0.5,0.5), #comentário sobre este ponto (qualquer um, só para aparecer a caixa)
            xytext=(4, 0.5), #posição do texto
            fontsize=10,
             color='red')

plt.show()

"""## Feature Engineer

**Attribute Information:**

* Date : (DD/MM/YYYY) Day, month ('june' to 'september'), year (2012)
* Temp : temperature noon (temperature max) in Celsius degrees: 22 to 42
* RH : Relative Humidity in %: 21 to 90
* Ws :Wind speed in km/h: 6 to 29
* Rain: total day in mm: 0 to 16.8 FWI Components
* Fine Fuel Moisture Code (FFMC) index from the FWI system: 28.6 to 92.5
* Duff Moisture Code (DMC) index from the FWI system: 1.1 to 65.9
* Drought Code (DC) index from the FWI system: 7 to 220.4
* Initial Spread Index (ISI) index from the FWI system: 0 to 18.5
* Buildup Index (BUI) index from the FWI system: 1.1 to 68
* Fire Weather Index (FWI) Index: 0 to 31.1
* Classes: two classes, namely Fire and not Fire
"""

df3 = df2.copy()

df3.columns

df3 = df3.drop(['index','day','month','year'],axis=1)

dummies_class_fire = pd.get_dummies(df3['class_fire']).astype(int) #só para treinar codificação, porque não faz sentido usar essa variável, dados que é derivada da resposta
df4 = pd.concat([df3,dummies_class_fire],axis=1)

df4 = df4.drop(['class_fire','not fire'],axis=1)

#verifica todas as variáveis
plt.style.use('seaborn')
df4.hist(bins=50,figsize=(20,15))

df4['Region'].value_counts(normalize=1)

df4['fire'].value_counts(normalize=1)

"""**Correlation**"""

#somente entre features
sns.heatmap(df4.drop(['FWI'],axis=1).corr(), cmap='seismic', annot=True, fmt=".2f")

"""As variáveis"""

#somente com a resposta
corr_target = df4.corr()[['FWI']].sort_values('FWI',ascending=False)
sns.heatmap(corr_target, cmap='seismic', annot=True, fmt=".2f",center=0)

"""Considerando a correlação entre as variáveis e a correlação de cada variável com a resposta, seria adequado remover as variáveis BUI e DC.

Também removeremos a variável fire, uma vez que ela pode ser usada para prever FWI.
"""

sns.heatmap(df4.drop(['FWI','DMC','BUI','fire'],axis=1).corr(), cmap='seismic', annot=True, fmt=".2f")

"""## Model training"""

X = df4[['Temperature', 'RH', 'Ws', 'Rain', 'FFMC', 'DMC', 'DC', 'ISI', 'BUI','Region']]
y = df4[['FWI']]

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=22)

"""**Feature Standartization**"""

scaler = StandardScaler()
X_train_std = scaler.fit_transform(X_train)
X_test_std = scaler.transform(X_test)

#analisar impact do standarscaler
#plt.boxplot(X_train)
#plt.boxplot(X_train_std)

"""**Training + Metric evaluation: Regressão linear**"""

#treinamento do modelo
model = LinearRegression()
model.fit(X_train_std,y_train)

#avalia métrica na base de treino e teste
y_pred_train = model.predict(X_train_std)
y_pred_test = model.predict(X_test_std)

mae_train = mean_absolute_error(y_pred_train, y_train)
r2_train = r2_score(y_pred_train, y_train)
rmse_train = mean_squared_error(y_pred_train, y_train)**(1/2)
mae_test = mean_absolute_error(y_pred_test, y_test)
r2_test = r2_score(y_pred_test, y_test)
rmse_test = mean_squared_error(y_pred_test, y_test)**(1/2)

print('MAE treino:',mae_train,' | R² treino: ',r2_train,' | RSME treino: ',rmse_train)
print('MAE teste:',mae_test,' | R² teste: ',r2_test,' | RSME teste: ',rmse_test)

"""**Training + Metric evaluation: Regressão Lasso**"""

#treinamento do modelo
model_lasso = Lasso()
model_lasso.fit(X_train_std,y_train)

#avalia métrica na base de treino e teste
y_pred_train_lasso = model_lasso.predict(X_train_std)
y_pred_test_lasso = model_lasso.predict(X_test_std)

mae_train_lasso = mean_absolute_error(y_pred_train_lasso, y_train)
r2_train_lasso = r2_score(y_pred_train_lasso, y_train)
rmse_train_lasso = mean_squared_error(y_pred_train_lasso, y_train)**(1/2)
mae_test_lasso = mean_absolute_error(y_pred_test_lasso, y_test)
r2_test_lasso = r2_score(y_pred_test_lasso, y_test)
rmse_test_lasso = mean_squared_error(y_pred_test_lasso, y_test)**(1/2)

print('MAE treino:',mae_train_lasso,' | R² treino: ',r2_train_lasso,' | RSME treino: ',rmse_train_lasso)
print('MAE teste:',mae_test_lasso,' | R² teste: ',r2_test_lasso,' | RSME teste: ',rmse_test_lasso)

"""**Training + Metric evaluation: Regressão Ridge**"""

#treinamento do modelo
model_ridge = Ridge()
model_ridge.fit(X_train_std,y_train)

#avalia métrica na base de treino e teste
y_pred_train_ridge = model_ridge.predict(X_train_std)
y_pred_test_ridge = model_ridge.predict(X_test_std)

mae_train_ridge = mean_absolute_error(y_pred_train_ridge, y_train)
r2_train_ridge = r2_score(y_pred_train_ridge, y_train)
rmse_train_ridge = mean_squared_error(y_pred_train_ridge, y_train)**(1/2)
mae_test_ridge = mean_absolute_error(y_pred_test_ridge, y_test)
r2_test_ridge = r2_score(y_pred_test_ridge, y_test)
rmse_test_ridge = mean_squared_error(y_pred_test_ridge, y_test)**(1/2)

print('MAE treino:',mae_train_ridge,' | R² treino: ',r2_train_ridge,' | RSME treino: ',rmse_train_ridge)
print('MAE teste:',mae_test_ridge,' | R² teste: ',r2_test_ridge,' | RSME teste: ',rmse_test_ridge)

"""**Training + Metric evaluation: Regressão ElasticNet**"""

#treinamento do modelo
model_elastic = ElasticNet()
model_elastic.fit(X_train_std,y_train)

#avalia métrica na base de treino e teste
y_pred_train_elastic = model_elastic.predict(X_train_std)
y_pred_test_elastic = model_elastic.predict(X_test_std)

mae_train_elastic = mean_absolute_error(y_pred_train_elastic, y_train)
r2_train_elastic = r2_score(y_pred_train_elastic, y_train)
rmse_train_elastic = mean_squared_error(y_pred_train_elastic, y_train)**(1/2)
mae_test_elastic = mean_absolute_error(y_pred_test_elastic, y_test)
r2_test_elastic = r2_score(y_pred_test_elastic, y_test)
rmse_test_elastic = mean_squared_error(y_pred_test_elastic, y_test)**(1/2)

print('MAE treino:',mae_train_elastic,' | R² treino: ',r2_train_elastic,' | RSME treino: ',rmse_train_elastic)
print('MAE teste:',mae_test_elastic,' | R² teste: ',r2_test_elastic,' | RSME teste: ',rmse_test_elastic)

"""**Resumo comparativo**"""

#Resumo
print('__________Regressão Linear')
print('MAE treino:',mae_train,' | R² treino: ',r2_train,' | RSME treino: ',rmse_train)
print('MAE teste:',mae_test,' | R² teste: ',r2_test,' | RSME teste: ',rmse_test)
print('__________Regressão Lasso')
print('MAE treino:',mae_train_lasso,' | R² treino: ',r2_train_lasso,' | RSME treino: ',rmse_train_lasso)
print('MAE teste:',mae_test_lasso,' | R² teste: ',r2_test_lasso,' | RSME teste: ',rmse_test_lasso)
print('__________Regressão Ridge')
print('MAE treino:',mae_train_ridge,' | R² treino: ',r2_train_ridge,' | RSME treino: ',rmse_train_ridge)
print('MAE teste:',mae_test_ridge,' | R² teste: ',r2_test_ridge,' | RSME teste: ',rmse_test_ridge)
print('__________Regressão Elastic Net')
print('MAE treino:',mae_train_elastic,' | R² treino: ',r2_train_elastic,' | RSME treino: ',rmse_train_elastic)
print('MAE teste:',mae_test_elastic,' | R² teste: ',r2_test_elastic,' | RSME teste: ',rmse_test_elastic)

"""*As regressões Linear e Ridge apresentaram resultados semelhantes, porém com indicação de overfitting.*

## Add Cross Validation

**Training + Metric evaluation: Regressão Ridge com Cross Validation**
"""

#treinamento do modelo
model_ridge_cv = RidgeCV(cv=10)
model_ridge_cv.fit(X_train_std,y_train)

#avalia métrica na base de treino e teste
y_pred_train_ridge_cv = model_ridge_cv.predict(X_train_std)
y_pred_test_ridge_cv = model_ridge_cv.predict(X_test_std)

mae_train_ridge_cv = mean_absolute_error(y_pred_train_ridge_cv, y_train)
r2_train_ridge_cv = r2_score(y_pred_train_ridge_cv, y_train)
rmse_train_ridge_cv = mean_squared_error(y_pred_train_ridge_cv, y_train)**(1/2)
mae_test_ridge_cv = mean_absolute_error(y_pred_test_ridge_cv, y_test)
r2_test_ridge_cv = r2_score(y_pred_test_ridge_cv, y_test)
rmse_test_ridge_cv = mean_squared_error(y_pred_test_ridge_cv, y_test)**(1/2)

print('MAE treino:',mae_train_ridge_cv,' | R² treino: ',r2_train_ridge_cv,' | RSME treino: ',rmse_train_ridge_cv)
print('MAE teste:',mae_test_ridge_cv,' | R² teste: ',r2_test_ridge_cv,' | RSME teste: ',rmse_test_ridge_cv)

print('__________Regressão Ridge')
print('MAE treino:',mae_train_ridge,' | R² treino: ',r2_train_ridge,' | RSME treino: ',rmse_train_ridge)
print('MAE teste:',mae_test_ridge,' | R² teste: ',r2_test_ridge,' | RSME teste: ',rmse_test_ridge)

"""O cross validation adicionou pouca diferença."""